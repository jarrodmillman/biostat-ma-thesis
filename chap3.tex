\chapter{\label{ch:func}Current functionality}

While the scope of our package is large, we have initially focused on a
few features.  In particular, we have implemented built-in datasets,
functions for exploratory data analysis, core functionality like various
types of permutations and confidence intervals, some stratified tests
and confidence sets, and a novel test for interrater reliability.

\section{Data}

To simplify testing as well as providing some standard datasets for
users to experiment with as they learn how our software works, we
have a data module, which provides quick and ready access to a few
built-in datasets. At this point, the majority of the datasets come
from the examples used in ``Permutation tests for complex data: theory,
applications and software'' \cite{pesarin2010permutation}.  These
datasets are discussed in more details in \S~\ref{sec:book}.  We also
have a data set, which we use as an example for the interrater
reliability test (\S~\ref{sec:irr}).

%Loading one of the packaged datasets involves importing and then
%invoking a helper function, which handles the data loading.  For
%example, here is how you would load the data set used for the
%interrater reliability test:
%\begin{verbatim}
%In [1]: from permute.data import nsgk
%
%In [2]: x = nsgk()
%\end{verbatim} 

\section{Exploratory data analysis}

As we've added datasets, we've also incrementally added tools to simplify
exploratory data analysis (EDA).  Currently, we provide two helper functions.
One for reporting duplicate rows in a matrix in various formats.  Another for
reporting duplicate consecutive rows in a matrix in various formats.  Rather
than having a list of planned EDA functionality, we have been opportunistic
and have only implemented functionality as needed for datasets we are adding
to the \texttt{data} module.

\section{Core tools}

The \texttt{core} module contains basic functions that could be useful in
multiple specific permutation tests as well as a few classic permutation tests.
This includes core functions for permuting various data structures in different
ways.  For example, we have functions for permuting the rows of a matrix
in-place as well as permuting conditions within each group. We also have
functions for computing confidence intervals for a binomial as well as
one- or two-sided, two-sample permutation test for equality of two means.

While one of our collaborators, Anne Boring from OFCE-Sciences Po in Paris, was
visiting to work on a study evaluating bias in student evaluations of teachers
\cite{boring2015}, we added code to simulate permutation p-value for Spearman
correlation coefficient.

\section{Stratified permutation testing}

This module contains code adapted from an IPython notebook written by
Philip demonstrating how to perform stratified permutation testing.

Test statistics in each stratum ...

Methods of combining tests across strata ...

Nonparametric combinations of tests ...

\section{\label{sec:irr}Interrater reliability}

The interrater reliability module was motivated by a specific problem presented
to us by Naomi Stark.  This data was collected under the following conditions.
Several different raters watched several videos.  Each video was paused at
regular intervals and each rater was asked to complete a checklist indicating
whether or not some event occurred in the video segment they just
viewed.\footnote{In fact, they were asked whether several different events
occurred in the video segment, but we consider each event separately.  So for
the purpose of this report, we will assume that there is only one event that is
either present or absent during each video segement.} The question posed to us
was to determine whether these responses (or ratings) were reliable between
raters. 

For each video and rater, we have a vector of 0s and 1s indicating whether the
event occurred or not during each time interval.  Under the null hypothesis, we
assume that the elements of the vector are exchangeable.  So the permutation
distribution is derived from permuting each rater's ratings independently.  For
our test statistic, we count the number of concordant pairs.

In 1960, Cohen \cite{cohen1960} introduced the kappa statistic for measuring
the agreement between two raters correcting for chance.  Since then a number of
extensions have been proposed, but we were unable to find one that provided a
stratified permutation test for multiple raters. We developed our own based
on a proposal by Philip Stark. The complete details of our method are included
in the documentation and is implemented with tests in our code.  We are in the
process of writing a manuscript to explain the method.


%The test statistic within stratum $s$ is
%
%\begin{align*}
%\rho_s &\equiv \frac{1}{N_s {R \choose 2}} \sum_{i=1}^{N_s}
%              \sum_{r=1}^{R-1} \sum_{v=r+1}^R 1(L_{s,i,r} = L_{s,i,v}) \\
%       &= \frac{1}{N_s R(R-1)} \sum_{i=1}^{N_s}
%                (y_{si}(y_{si}-1) + (R-y_{si})(R-y_{si}-1)).
%\end{align*}

%That is, within each stratum, we count the number of concordant pairs of
%assignments.

